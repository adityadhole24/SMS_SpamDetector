# -*- coding: utf-8 -*-
"""SmsSpamFilter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nb54AC1BvoDfs9pvDOYDiAer9hWbP2_p
"""

import numpy as np
import pandas as pd
import seaborn as sn
import re
import nltk
nltk.download('stopwords')
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report 
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn import metrics, svm
from sklearn.model_selection import (
    train_test_split, learning_curve, StratifiedShuffleSplit, GridSearchCV,
    cross_val_score)

# Load the dataset
df = pd.read_table('/content/SMSSpamCollection.txt', header=None)
df.head()

df.info()

# Store the target variable
y = df[0]

# Display the class distribution
y.value_counts()

# Encode the class labels as numbers
le = LabelEncoder()
y_enc = le.fit_transform(y)

print(y_enc)

# Store the SMS message data
raw_text = df[1]

# Access stop words
stop_words = nltk.corpus.stopwords.words('english')

# Remove word stems using a Porter stemmer
porter = nltk.PorterStemmer()



def preprocess_text(messy_string):
    assert(type(messy_string) == str)
    cleaned = re.sub(r'\b[\w\-.]+?@\w+?\.\w{2,4}\b', 'emailaddr', messy_string)
    cleaned = re.sub(r'(http[s]?\S+)|(\w+\.[A-Za-z]{2,4}\S*)', 'httpaddr',
                     cleaned)
    cleaned = re.sub(r'Â£|\$', 'moneysymb', cleaned)
    cleaned = re.sub(
        r'\b(\+\d{1,2}\s)?\d?[\-(.]?\d{3}\)?[\s.-]?\d{3}[\s.-]?\d{4}\b',
        'phonenumbr', cleaned)
    cleaned = re.sub(r'\d+(\.\d+)?', 'numbr', cleaned)
    cleaned = re.sub(r'[^\w\d\s]', ' ', cleaned)
    cleaned = re.sub(r'\s+', ' ', cleaned)
    cleaned = re.sub(r'^\s+|\s+?$', '', cleaned.lower())
    return ' '.join(
        porter.stem(term) 
        for term in cleaned.split()
        if term not in set(stop_words)
    )

example = """  ***** CONGRATlations **** You won 2 tIckETs to Hamilton in 
NYC http://www.hamiltonbroadway.com/J?NaIOl/event   wORtH over $500.00...CALL 
555-477-8914 or send message to: hamilton@freetix.com to get ticket !! !  """


preprocess_text(example)

processed=raw_text.apply(preprocess_text)

# Construct a design matrix using an n-gram model and a tf-idf statistics
vectorizer = TfidfVectorizer(ngram_range=(1, 2))
X_ngrams = vectorizer.fit_transform(processed)

X_ngrams.shape

# Prepare the training and test sets using an 80/20 split
X_train, X_test, y_train, y_test = train_test_split(
    X_ngrams,
    y_enc,
    test_size=0.2,
    random_state=42,
    stratify=y_enc
)

# Train SVM with a linear kernel on the training set
clf = svm.LinearSVC(loss='hinge')
clf.fit(X_train, y_train)

# Evaluate the classifier on the test set
y_pred = clf.predict(X_test)

# Compute the F1 score
metrics.f1_score(y_test, y_pred)

#Generate Classification Report
print(classification_report(y_test,y_pred))

# Display a confusion matrix
df_cm =pd.DataFrame(
    metrics.confusion_matrix(y_test, y_pred),
    index=[['actual', 'actual'], ['spam', 'ham']],
    columns=[['predicted', 'predicted'], ['spam', 'ham']]
)

sn.set(font_scale=1.4)#for label size
sn.heatmap(df_cm, fmt='d', annot=True,annot_kws={"size": 16})# font size

def spam_filter(message):
    if clf.predict(vectorizer.transform([preprocess_text(message)])):
        return 'spam'
    else:
        return 'not spam'

spam_filter(example)

spam_filter('Ohhh, but those are the best kind of foods')

